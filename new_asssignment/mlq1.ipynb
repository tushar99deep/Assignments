{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b004dfdf",
   "metadata": {},
   "source": [
    "# Q-1. Imagine you have a dataset where you have different Instagram features\n",
    "like u sername , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task is\n",
    "to predict the number of likes and Time Since posted and the rest of the features are your input features. Now you have to build a model which can predict the\n",
    "number of likes and Time Since posted.\n",
    "Dataset This is the Dataset You can use this dataset for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ebaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('mlq1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef893cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85321737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unnamed: 0','S.No'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51329028",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e69691",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time since posted']=data['Time since posted'].apply(lambda x :x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time since posted']=data['Time since posted'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092958d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into input features (X) and target variables (y)\n",
    "X = data.drop(['Likes', 'Time since posted'], axis=1)\n",
    "y_likes = data['Likes']\n",
    "y_time_since_posted = data['Time since posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_likes = RandomForestRegressor()\n",
    "\n",
    "# Choose the algorithm for predicting time since posted\n",
    "model_time_since_posted = RandomForestRegressor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87174b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_likes_train, y_likes_test, y_time_since_posted_train, y_time_since_posted_test = train_test_split(\n",
    "    X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e47a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2e588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a731554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c963dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e99409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7df7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5c707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_likes_train, y_likes_test, y_time_since_posted_train, y_time_since_posted_test = train_test_split(\n",
    "    X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the column transformer for numerical and categorical features\n",
    "numerical_features = ['Followers']\n",
    "categorical_features1 = ['Caption','Hashtags']\n",
    "\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac802e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b2a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d085e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81bd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cf55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Likes', 'Time since posted'], axis=1)\n",
    "y_likes = data['Likes']\n",
    "y_time_since_posted = data['Time since posted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Selection\n",
    "# Choose the algorithm for predicting likes\n",
    "model_likes = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the algorithm for predicting time since posted\n",
    "model_time_since_posted = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_likes_train, y_likes_test, y_time_since_posted_train, y_time_since_posted_test = train_test_split(\n",
    "    X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5287cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer= SimpleImputer()\n",
    "imputer.fit_transform(X_train)\n",
    "imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the models on the training data\n",
    "model_likes.fit(X_train, y_likes_train)\n",
    "model_time_since_posted.fit(X_train, y_time_since_posted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Evaluation\n",
    "# Predict on the test set for likes\n",
    "y_likes_pred = model_likes.predict(X_test)\n",
    "mse_likes = mean_squared_error(y_likes_test, y_likes_pred)\n",
    "rsquare = r2_score(y_likes_test, y_likes_pred)\n",
    "print(\"Mean Squared Error (Likes):\", mse_likes)\n",
    "print(\"R2 SCore (Likes):\", rsquare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_likes1 = RandomForestRegressor()\n",
    "\n",
    "# Choose the algorithm for predicting time since posted\n",
    "model_time_since_posted1 = RandomForestRegressor()\n",
    "\n",
    "\n",
    "# Fit the models on the training data\n",
    "model_likes1.fit(X_train, y_likes_train)\n",
    "model_time_since_posted1.fit(X_train, y_time_since_posted_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_likes_pred1 = model_likes1.predict(X_test)\n",
    "mse_likes1 = mean_squared_error(y_likes_test, y_likes_pred1)\n",
    "rsquare1= r2_score(y_likes_test, y_likes_pred1)\n",
    "print(\"rsquare1:\", rsquare1)\n",
    "print(\"Mean Squared Error (Likes):\", mse_likes1)\n",
    "\n",
    "# Predict on the test set for time since posted\n",
    "y_time_since_posted_pred1 = model_time_since_posted1.predict(X_test)\n",
    "mse_time_since_posted1 = mean_squared_error(y_time_since_posted_test, y_time_since_posted_pred1)\n",
    "print(\"Mean Squared Error (Time Since Posted):\", mse_time_since_posted1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b01ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "55601330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Followers</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "      <th>USERNAME__ehab.othman_</th>\n",
       "      <th>USERNAME__linda_smith567</th>\n",
       "      <th>USERNAME_ah_studio_</th>\n",
       "      <th>USERNAME_aitrading_official</th>\n",
       "      <th>USERNAME_ale_borba</th>\n",
       "      <th>USERNAME_alpha_mentor_</th>\n",
       "      <th>USERNAME_amjstaffing</th>\n",
       "      <th>...</th>\n",
       "      <th>Hashtags_#weekend #chill #chilling #Summer#founder #startup #smallbusiness #smallbiz#contentmarketing #consulting</th>\n",
       "      <th>Hashtags_#whoiswho #aitrading #ai #aitradingteam#instateam #instapeople #ai #trading#artificialintelligence #crypto#cryptocurrency #blockchain #tradingforex#forex #fiatmoney #coins #machinelearning#userexperience #instamachinelearning#instabigdata #instamarketing#artificialintelligence #deeplearning#datascience #industry #marketing#bigdata #datascience #machinelearning#ml</th>\n",
       "      <th>Hashtags_#worldcode #coding#python #codeaholics #rstudio #codinglife#worldofprogrammers #datascience#machinelearning #dataviz #data #statistics#macbookpro #peoplewhocode#codeismylife #datavisualization#artificialintelligence #digitalnomads#digitalnomad #travel</th>\n",
       "      <th>Hashtags_#youtube #applemusic #itunes#soundcloud #spinrilla #spotify #bigdata#blockchain #dontbandwagonlater</th>\n",
       "      <th>Hashtags_#любовь #gm #sme #smenigeria #profits#businessowners #businessplan#entrepreneurship #entrepreneur#blockchain #crypto #cointelegraph#bitcoinprice #mining #cryptocurrencies#bch #bitcoins #litecoin #investment#investor #stockmarket #stocks #getrich#makemoney #makemoneyonline#mentorship #mentoring #xrp #bitfinex#altcoins</th>\n",
       "      <th>Hashtags_.#Tech ",
       "#virtualreality ",
       "#IoT ",
       "#Machinelearning</th>\n",
       "      <th>Hashtags_[#Infographic] #Wearable #Sensors #MachineLearning#IoT #BigData #DigitalTransformation#futureofwork #marketing #analytics#bigdata #Cloud #Blogging#ContentMarketing #DigitalMarketing ht: #BigData #MachineLearning #AI #IoT#infograp</th>\n",
       "      <th>Hashtags_thebeautymindset#businessman#quoteoftheday #businessowner#businesswoman #success #grind#motivation #motivational #lifestyle#happiness #entrepreneurs#entrepreneurlife #business #working #founder#startup #money #magazine #moneymaker#startuplife #successful #passion #inspiredaily#hardwork #hardworkpaysoff #desire</th>\n",
       "      <th>Hashtags_ #datascience #data #tech #technology#future #machinelearning #ai#visualizations #dataisbeautiful</th>\n",
       "      <th>Hashtags_ #deck .#mac #macintosh#sayhello #apple #stevejobs #ai #evolution#artificialintelligence #machinelearning#terminator #illbeback #technology#computerevolution #computerscience#sciencefiction#computersciencetosciencefiction#tomorrowstechnology #vr #ar #robot#robots #t2 #businessdeck #businessslides#illustration #sketches #drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>880.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>888.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>845.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 1011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Followers  Time since posted  Likes  USERNAME__ehab.othman_  \\\n",
       "0      1600.0               11.0  139.0                     0.0   \n",
       "1       880.0                2.0   23.0                     0.0   \n",
       "2       255.0                2.0   25.0                     0.0   \n",
       "3       340.0                3.0   49.0                     0.0   \n",
       "4       304.0                3.0   30.0                     0.0   \n",
       "..        ...                ...    ...                     ...   \n",
       "81      888.0                2.0   43.0                     0.0   \n",
       "82      845.0                2.0   31.0                     0.0   \n",
       "52        NaN                NaN    NaN                     NaN   \n",
       "67        NaN                NaN    NaN                     NaN   \n",
       "72        NaN                NaN    NaN                     NaN   \n",
       "\n",
       "    USERNAME__linda_smith567  USERNAME_ah_studio_  \\\n",
       "0                        0.0                  0.0   \n",
       "1                        0.0                  0.0   \n",
       "2                        0.0                  0.0   \n",
       "3                        0.0                  0.0   \n",
       "4                        0.0                  0.0   \n",
       "..                       ...                  ...   \n",
       "81                       0.0                  0.0   \n",
       "82                       0.0                  0.0   \n",
       "52                       NaN                  NaN   \n",
       "67                       NaN                  NaN   \n",
       "72                       NaN                  NaN   \n",
       "\n",
       "    USERNAME_aitrading_official  USERNAME_ale_borba  USERNAME_alpha_mentor_  \\\n",
       "0                           0.0                 0.0                     0.0   \n",
       "1                           0.0                 0.0                     0.0   \n",
       "2                           1.0                 0.0                     0.0   \n",
       "3                           0.0                 0.0                     0.0   \n",
       "4                           0.0                 0.0                     0.0   \n",
       "..                          ...                 ...                     ...   \n",
       "81                          0.0                 0.0                     0.0   \n",
       "82                          0.0                 0.0                     0.0   \n",
       "52                          NaN                 NaN                     NaN   \n",
       "67                          NaN                 NaN                     NaN   \n",
       "72                          NaN                 NaN                     NaN   \n",
       "\n",
       "    USERNAME_amjstaffing  ...  \\\n",
       "0                    0.0  ...   \n",
       "1                    0.0  ...   \n",
       "2                    0.0  ...   \n",
       "3                    0.0  ...   \n",
       "4                    0.0  ...   \n",
       "..                   ...  ...   \n",
       "81                   0.0  ...   \n",
       "82                   0.0  ...   \n",
       "52                   NaN  ...   \n",
       "67                   NaN  ...   \n",
       "72                   NaN  ...   \n",
       "\n",
       "    Hashtags_#weekend #chill #chilling #Summer#founder #startup #smallbusiness #smallbiz#contentmarketing #consulting  \\\n",
       "0                                                 0.0                                                                   \n",
       "1                                                 0.0                                                                   \n",
       "2                                                 0.0                                                                   \n",
       "3                                                 0.0                                                                   \n",
       "4                                                 0.0                                                                   \n",
       "..                                                ...                                                                   \n",
       "81                                                NaN                                                                   \n",
       "82                                                NaN                                                                   \n",
       "52                                                0.0                                                                   \n",
       "67                                                0.0                                                                   \n",
       "72                                                0.0                                                                   \n",
       "\n",
       "    Hashtags_#whoiswho #aitrading #ai #aitradingteam#instateam #instapeople #ai #trading#artificialintelligence #crypto#cryptocurrency #blockchain #tradingforex#forex #fiatmoney #coins #machinelearning#userexperience #instamachinelearning#instabigdata #instamarketing#artificialintelligence #deeplearning#datascience #industry #marketing#bigdata #datascience #machinelearning#ml  \\\n",
       "0                                                 0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "1                                                 0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "2                                                 1.0                                                                                                                                                                                                                                                                                                                                        \n",
       "3                                                 0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "4                                                 0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "..                                                ...                                                                                                                                                                                                                                                                                                                                        \n",
       "81                                                NaN                                                                                                                                                                                                                                                                                                                                        \n",
       "82                                                NaN                                                                                                                                                                                                                                                                                                                                        \n",
       "52                                                0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "67                                                0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "72                                                0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "    Hashtags_#worldcode #coding#python #codeaholics #rstudio #codinglife#worldofprogrammers #datascience#machinelearning #dataviz #data #statistics#macbookpro #peoplewhocode#codeismylife #datavisualization#artificialintelligence #digitalnomads#digitalnomad #travel  \\\n",
       "0                                                 0.0                                                                                                                                                                                                                      \n",
       "1                                                 0.0                                                                                                                                                                                                                      \n",
       "2                                                 0.0                                                                                                                                                                                                                      \n",
       "3                                                 0.0                                                                                                                                                                                                                      \n",
       "4                                                 0.0                                                                                                                                                                                                                      \n",
       "..                                                ...                                                                                                                                                                                                                      \n",
       "81                                                NaN                                                                                                                                                                                                                      \n",
       "82                                                NaN                                                                                                                                                                                                                      \n",
       "52                                                0.0                                                                                                                                                                                                                      \n",
       "67                                                0.0                                                                                                                                                                                                                      \n",
       "72                                                0.0                                                                                                                                                                                                                      \n",
       "\n",
       "    Hashtags_#youtube #applemusic #itunes#soundcloud #spinrilla #spotify #bigdata#blockchain #dontbandwagonlater  \\\n",
       "0                                                 0.0                                                              \n",
       "1                                                 0.0                                                              \n",
       "2                                                 0.0                                                              \n",
       "3                                                 0.0                                                              \n",
       "4                                                 0.0                                                              \n",
       "..                                                ...                                                              \n",
       "81                                                NaN                                                              \n",
       "82                                                NaN                                                              \n",
       "52                                                0.0                                                              \n",
       "67                                                0.0                                                              \n",
       "72                                                0.0                                                              \n",
       "\n",
       "    Hashtags_#любовь #gm #sme #smenigeria #profits#businessowners #businessplan#entrepreneurship #entrepreneur#blockchain #crypto #cointelegraph#bitcoinprice #mining #cryptocurrencies#bch #bitcoins #litecoin #investment#investor #stockmarket #stocks #getrich#makemoney #makemoneyonline#mentorship #mentoring #xrp #bitfinex#altcoins  \\\n",
       "0                                                 0.0                                                                                                                                                                                                                                                                                         \n",
       "1                                                 0.0                                                                                                                                                                                                                                                                                         \n",
       "2                                                 0.0                                                                                                                                                                                                                                                                                         \n",
       "3                                                 0.0                                                                                                                                                                                                                                                                                         \n",
       "4                                                 0.0                                                                                                                                                                                                                                                                                         \n",
       "..                                                ...                                                                                                                                                                                                                                                                                         \n",
       "81                                                NaN                                                                                                                                                                                                                                                                                         \n",
       "82                                                NaN                                                                                                                                                                                                                                                                                         \n",
       "52                                                0.0                                                                                                                                                                                                                                                                                         \n",
       "67                                                0.0                                                                                                                                                                                                                                                                                         \n",
       "72                                                0.0                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "    Hashtags_.#Tech\n",
       "#virtualreality\n",
       "#IoT\n",
       "#Machinelearning  \\\n",
       "0                                                 0.0       \n",
       "1                                                 0.0       \n",
       "2                                                 0.0       \n",
       "3                                                 0.0       \n",
       "4                                                 0.0       \n",
       "..                                                ...       \n",
       "81                                                NaN       \n",
       "82                                                NaN       \n",
       "52                                                0.0       \n",
       "67                                                0.0       \n",
       "72                                                0.0       \n",
       "\n",
       "    Hashtags_[#Infographic] #Wearable #Sensors #MachineLearning#IoT #BigData #DigitalTransformation#futureofwork #marketing #analytics#bigdata #Cloud #Blogging#ContentMarketing #DigitalMarketing ht: #BigData #MachineLearning #AI #IoT#infograp  \\\n",
       "0                                                 0.0                                                                                                                                                                                                \n",
       "1                                                 0.0                                                                                                                                                                                                \n",
       "2                                                 0.0                                                                                                                                                                                                \n",
       "3                                                 0.0                                                                                                                                                                                                \n",
       "4                                                 0.0                                                                                                                                                                                                \n",
       "..                                                ...                                                                                                                                                                                                \n",
       "81                                                NaN                                                                                                                                                                                                \n",
       "82                                                NaN                                                                                                                                                                                                \n",
       "52                                                0.0                                                                                                                                                                                                \n",
       "67                                                0.0                                                                                                                                                                                                \n",
       "72                                                0.0                                                                                                                                                                                                \n",
       "\n",
       "    Hashtags_thebeautymindset#businessman#quoteoftheday #businessowner#businesswoman #success #grind#motivation #motivational #lifestyle#happiness #entrepreneurs#entrepreneurlife #business #working #founder#startup #money #magazine #moneymaker#startuplife #successful #passion #inspiredaily#hardwork #hardworkpaysoff #desire  \\\n",
       "0                                                 0.0                                                                                                                                                                                                                                                                                  \n",
       "1                                                 0.0                                                                                                                                                                                                                                                                                  \n",
       "2                                                 0.0                                                                                                                                                                                                                                                                                  \n",
       "3                                                 0.0                                                                                                                                                                                                                                                                                  \n",
       "4                                                 0.0                                                                                                                                                                                                                                                                                  \n",
       "..                                                ...                                                                                                                                                                                                                                                                                  \n",
       "81                                                NaN                                                                                                                                                                                                                                                                                  \n",
       "82                                                NaN                                                                                                                                                                                                                                                                                  \n",
       "52                                                0.0                                                                                                                                                                                                                                                                                  \n",
       "67                                                0.0                                                                                                                                                                                                                                                                                  \n",
       "72                                                0.0                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "    Hashtags_ #datascience #data #tech #technology#future #machinelearning #ai#visualizations #dataisbeautiful  \\\n",
       "0                                                 0.0                                                            \n",
       "1                                                 0.0                                                            \n",
       "2                                                 0.0                                                            \n",
       "3                                                 0.0                                                            \n",
       "4                                                 0.0                                                            \n",
       "..                                                ...                                                            \n",
       "81                                                NaN                                                            \n",
       "82                                                NaN                                                            \n",
       "52                                                0.0                                                            \n",
       "67                                                0.0                                                            \n",
       "72                                                0.0                                                            \n",
       "\n",
       "    Hashtags_ #deck .#mac #macintosh#sayhello #apple #stevejobs #ai #evolution#artificialintelligence #machinelearning#terminator #illbeback #technology#computerevolution #computerscience#sciencefiction#computersciencetosciencefiction#tomorrowstechnology #vr #ar #robot#robots #t2 #businessdeck #businessslides#illustration #sketches #drawing  \n",
       "0                                                 0.0                                                                                                                                                                                                                                                                                                   \n",
       "1                                                 1.0                                                                                                                                                                                                                                                                                                   \n",
       "2                                                 0.0                                                                                                                                                                                                                                                                                                   \n",
       "3                                                 0.0                                                                                                                                                                                                                                                                                                   \n",
       "4                                                 0.0                                                                                                                                                                                                                                                                                                   \n",
       "..                                                ...                                                                                                                                                                                                                                                                                                   \n",
       "81                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "82                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "52                                                0.0                                                                                                                                                                                                                                                                                                   \n",
       "67                                                0.0                                                                                                                                                                                                                                                                                                   \n",
       "72                                                0.0                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "[82 rows x 1011 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Handle missing data\n",
    "data = data.dropna()  # Remove rows with missing values\n",
    "\n",
    "# Convert categorical variables to numerical representations using one-hot encoding\n",
    "categorical_features = ['USERNAME', 'Caption', 'Hashtags']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = pd.DataFrame(encoder.fit_transform(data[categorical_features]))\n",
    "encoded_features.columns = encoder.get_feature_names_out(categorical_features)\n",
    "data = pd.concat([data, encoded_features], axis=1)\n",
    "data.drop(columns=['USERNAME', 'Caption', 'Hashtags'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "80030702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "      <th>USERNAME__ehab.othman_</th>\n",
       "      <th>USERNAME__linda_smith567</th>\n",
       "      <th>USERNAME_ah_studio_</th>\n",
       "      <th>USERNAME_aitrading_official</th>\n",
       "      <th>...</th>\n",
       "      <th>Hashtags_#weekend #chill #chilling #Summer#founder #startup #smallbusiness #smallbiz#contentmarketing #consulting</th>\n",
       "      <th>Hashtags_#whoiswho #aitrading #ai #aitradingteam#instateam #instapeople #ai #trading#artificialintelligence #crypto#cryptocurrency #blockchain #tradingforex#forex #fiatmoney #coins #machinelearning#userexperience #instamachinelearning#instabigdata #instamarketing#artificialintelligence #deeplearning#datascience #industry #marketing#bigdata #datascience #machinelearning#ml</th>\n",
       "      <th>Hashtags_#worldcode #coding#python #codeaholics #rstudio #codinglife#worldofprogrammers #datascience#machinelearning #dataviz #data #statistics#macbookpro #peoplewhocode#codeismylife #datavisualization#artificialintelligence #digitalnomads#digitalnomad #travel</th>\n",
       "      <th>Hashtags_#youtube #applemusic #itunes#soundcloud #spinrilla #spotify #bigdata#blockchain #dontbandwagonlater</th>\n",
       "      <th>Hashtags_#любовь #gm #sme #smenigeria #profits#businessowners #businessplan#entrepreneurship #entrepreneur#blockchain #crypto #cointelegraph#bitcoinprice #mining #cryptocurrencies#bch #bitcoins #litecoin #investment#investor #stockmarket #stocks #getrich#makemoney #makemoneyonline#mentorship #mentoring #xrp #bitfinex#altcoins</th>\n",
       "      <th>Hashtags_.#Tech ",
       "#virtualreality ",
       "#IoT ",
       "#Machinelearning</th>\n",
       "      <th>Hashtags_[#Infographic] #Wearable #Sensors #MachineLearning#IoT #BigData #DigitalTransformation#futureofwork #marketing #analytics#bigdata #Cloud #Blogging#ContentMarketing #DigitalMarketing ht: #BigData #MachineLearning #AI #IoT#infograp</th>\n",
       "      <th>Hashtags_thebeautymindset#businessman#quoteoftheday #businessowner#businesswoman #success #grind#motivation #motivational #lifestyle#happiness #entrepreneurs#entrepreneurlife #business #working #founder#startup #money #magazine #moneymaker#startuplife #successful #passion #inspiredaily#hardwork #hardworkpaysoff #desire</th>\n",
       "      <th>Hashtags_ #datascience #data #tech #technology#future #machinelearning #ai#visualizations #dataisbeautiful</th>\n",
       "      <th>Hashtags_ #deck .#mac #macintosh#sayhello #apple #stevejobs #ai #evolution#artificialintelligence #machinelearning#terminator #illbeback #technology#computerevolution #computerscience#sciencefiction#computersciencetosciencefiction#tomorrowstechnology #vr #ar #robot#robots #t2 #businessdeck #businessslides#illustration #sketches #drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        USERNAME                                            Caption  \\\n",
       "0  mikequindazzi  Who are #DataScientist and what do they do? >>...   \n",
       "\n",
       "   Followers                                           Hashtags  \\\n",
       "0     1600.0  #MachineLearning #AI #DataAnalytics #DataScien...   \n",
       "\n",
       "   Time since posted  Likes  USERNAME__ehab.othman_  USERNAME__linda_smith567  \\\n",
       "0               11.0  139.0                     0.0                       0.0   \n",
       "\n",
       "   USERNAME_ah_studio_  USERNAME_aitrading_official  ...  \\\n",
       "0                  0.0                          0.0  ...   \n",
       "\n",
       "   Hashtags_#weekend #chill #chilling #Summer#founder #startup #smallbusiness #smallbiz#contentmarketing #consulting  \\\n",
       "0                                                0.0                                                                   \n",
       "\n",
       "   Hashtags_#whoiswho #aitrading #ai #aitradingteam#instateam #instapeople #ai #trading#artificialintelligence #crypto#cryptocurrency #blockchain #tradingforex#forex #fiatmoney #coins #machinelearning#userexperience #instamachinelearning#instabigdata #instamarketing#artificialintelligence #deeplearning#datascience #industry #marketing#bigdata #datascience #machinelearning#ml  \\\n",
       "0                                                0.0                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "   Hashtags_#worldcode #coding#python #codeaholics #rstudio #codinglife#worldofprogrammers #datascience#machinelearning #dataviz #data #statistics#macbookpro #peoplewhocode#codeismylife #datavisualization#artificialintelligence #digitalnomads#digitalnomad #travel  \\\n",
       "0                                                0.0                                                                                                                                                                                                                      \n",
       "\n",
       "   Hashtags_#youtube #applemusic #itunes#soundcloud #spinrilla #spotify #bigdata#blockchain #dontbandwagonlater  \\\n",
       "0                                                0.0                                                              \n",
       "\n",
       "   Hashtags_#любовь #gm #sme #smenigeria #profits#businessowners #businessplan#entrepreneurship #entrepreneur#blockchain #crypto #cointelegraph#bitcoinprice #mining #cryptocurrencies#bch #bitcoins #litecoin #investment#investor #stockmarket #stocks #getrich#makemoney #makemoneyonline#mentorship #mentoring #xrp #bitfinex#altcoins  \\\n",
       "0                                                0.0                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "   Hashtags_.#Tech\n",
       "#virtualreality\n",
       "#IoT\n",
       "#Machinelearning  \\\n",
       "0                                                0.0       \n",
       "\n",
       "   Hashtags_[#Infographic] #Wearable #Sensors #MachineLearning#IoT #BigData #DigitalTransformation#futureofwork #marketing #analytics#bigdata #Cloud #Blogging#ContentMarketing #DigitalMarketing ht: #BigData #MachineLearning #AI #IoT#infograp  \\\n",
       "0                                                0.0                                                                                                                                                                                                \n",
       "\n",
       "   Hashtags_thebeautymindset#businessman#quoteoftheday #businessowner#businesswoman #success #grind#motivation #motivational #lifestyle#happiness #entrepreneurs#entrepreneurlife #business #working #founder#startup #money #magazine #moneymaker#startuplife #successful #passion #inspiredaily#hardwork #hardworkpaysoff #desire  \\\n",
       "0                                                0.0                                                                                                                                                                                                                                                                                  \n",
       "\n",
       "   Hashtags_ #datascience #data #tech #technology#future #machinelearning #ai#visualizations #dataisbeautiful  \\\n",
       "0                                                0.0                                                            \n",
       "\n",
       "   Hashtags_ #deck .#mac #macintosh#sayhello #apple #stevejobs #ai #evolution#artificialintelligence #machinelearning#terminator #illbeback #technology#computerevolution #computerscience#sciencefiction#computersciencetosciencefiction#tomorrowstechnology #vr #ar #robot#robots #t2 #businessdeck #businessslides#illustration #sketches #drawing  \n",
       "0                                                0.0                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "[1 rows x 1014 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7f24cfc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'interplayofficial'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[300], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m X_train, X_test, y_likes_train, y_likes_test, y_time_since_posted_train, y_time_since_posted_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     18\u001b[0m     X, y_likes, y_time_since_posted, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fit the models on the training data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel_likes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_likes_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model_time_since_posted\u001b[38;5;241m.\u001b[39mfit(X_train, y_time_since_posted_train)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Step 5: Model Evaluation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Predict on the test set for likes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'interplayofficial'"
     ]
    }
   ],
   "source": [
    "# Split the dataset into input features (X) and target variables (y)\n",
    "X = data.drop(['Likes', 'Time since posted'], axis=1)\n",
    "y_likes = data['Likes']\n",
    "y_time_since_posted = data['Time since posted']\n",
    "\n",
    "# Step 2: Feature Engineering (No additional features added in this example)\n",
    "\n",
    "# Step 3: Model Selection\n",
    "# Choose the algorithm for predicting likes\n",
    "model_likes = LinearRegression()\n",
    "\n",
    "# Choose the algorithm for predicting time since posted\n",
    "model_time_since_posted = LinearRegression()\n",
    "\n",
    "# Step 4: Model Training\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_likes_train, y_likes_test, y_time_since_posted_train, y_time_since_posted_test = train_test_split(\n",
    "    X, y_likes, y_time_since_posted, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the models on the training data\n",
    "model_likes.fit(X_train, y_likes_train)\n",
    "model_time_since_posted.fit(X_train, y_time_since_posted_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "# Predict on the test set for likes\n",
    "y_likes_pred = model_likes.predict(X_test)\n",
    "mse_likes = mean_squared_error(y_likes_test, y_likes_pred)\n",
    "print(\"Mean Squared Error (Likes):\", mse_likes)\n",
    "\n",
    "# Predict on the test set for time since posted\n",
    "y_time_since_posted_pred = model_time_since_posted.predict(X_test)\n",
    "mse_time_since_posted = mean_squared_error(y_time_since_posted_test, y_time_since_posted_pred)\n",
    "print(\"Mean Squared Error (Time Since Posted):\", mse_time_since_posted)\n",
    "\n",
    "# Step 6: Model Optimization (No additional optimization in this example)\n",
    "\n",
    "# Step 7: Model Prediction (Using the trained model to make predictions on new data)\n",
    "# Assuming you have a new data point 'new_data' with the same features as X\n",
    "new_data = pd.DataFrame({\n",
    "    'USERNAME': ['john_doe'],\n",
    "    'Caption': ['Great day at the beach!'],\n",
    "    'Hashtags': ['#beach', '#fun'],\n",
    "    'Followers': [1000],\n",
    "    'Time since posted': [10]\n",
    "})\n",
    "\n",
    "# Convert categorical variables to numerical representations using one-hot encoding\n",
    "encoded_new_data = pd.DataFrame(encoder.transform(new_data[categorical_features]))\n",
    "encoded_new_data.columns = encoder.get_feature_names(categorical_features)\n",
    "new_data = pd.concat([new_data, encoded_new_data], axis=1)\n",
    "new_data = new_data.drop(categorical_features, axis=1)\n",
    "\n",
    "# Make predictions\n",
    "new_likes_pred = model_likes.predict(new_data)\n",
    "new_time_since_posted_pred = model_time_since_posted.predict(new_data)\n",
    "\n",
    "print(\"Predicted Likes:\", new_likes_pred)\n",
    "print(\"Predicted Time Since Posted:\", new_time_since_posted_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184334a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the algorithm for predicting likes\n",
    "model_likes = RandomForestRegressor()\n",
    "\n",
    "# Choose the algorithm for predicting time since posted\n",
    "model_time_since_posted = RandomForestRegressor()\n",
    "\n",
    "model_likes.fit(X_train, y_likes_train)\n",
    "\n",
    "\n",
    "model_time_since_posted.fit(X_train, y_time_since_posted_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "# Predict on the test set for likes\n",
    "y_likes_pred = model_likes.predict(X_test)\n",
    "mse_likes = mean_squared_error(y_likes_test, y_likes_pred)\n",
    "print(\"Mean Squared Error (Likes):\", mse_likes)\n",
    "\n",
    "# Predict on the test set for time since posted\n",
    "y_time_since_posted_pred = model_time_since_posted.predict(X_test)\n",
    "mse_time_since_posted = mean_squared_error(y_time_since_posted_test, y_time_since_posted_pred)\n",
    "print(\"Mean Squared Error (Time Since Posted):\", mse_time_since_posted)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
